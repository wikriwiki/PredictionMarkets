{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from clob_client import PolymarketClient,timestamp_to_datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PolymarketClient 초기화\n",
    "client = PolymarketClient()\n",
    "\n",
    "# 입력 데이터 읽기 \n",
    "matching_df = pd.read_csv('merged_result.csv')\n",
    "questions = matching_df['matching_questions'].tolist()\n",
    "dates = matching_df['upload_date'].tolist() \n",
    "\n",
    "# condition_id 매핑 (예: closed_trump_questions_description.csv)\n",
    "closed_trump_df = pd.read_csv('closed_trump_questions_description.csv')\n",
    "condition_ids = []\n",
    "for question in questions:\n",
    "    matched_row = closed_trump_df[closed_trump_df['question'] == question]\n",
    "    if not matched_row.empty:\n",
    "        condition_ids.append(matched_row.iloc[0]['condition_id'])\n",
    "    else:\n",
    "        condition_ids.append(None)\n",
    "        \n",
    "# 결과를 저장할 리스트\n",
    "results = []\n",
    "\n",
    "# 변동을 계산할 날짜 오프셋 (1일, 3일, 5일 후)\n",
    "offsets = [1, 3, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8316\\3519153323.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mclob_client\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPolymarketClient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimestamp_to_datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlru_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\han\\anaconda3\\envs\\keybert_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4089\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4091\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4092\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4093\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4095\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4096\u001b[0m         \u001b[1;31m# We interpret tuples as collections only for non-MultiIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\han\\anaconda3\\envs\\keybert_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4154\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#가격 레이블링\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from clob_client import PolymarketClient,timestamp_to_datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "\n",
    "# PolymarketClient 초기화\n",
    "client = PolymarketClient()\n",
    "\n",
    "# 캐싱을 위한 함수 정의\n",
    "@lru_cache(maxsize=100)\n",
    "def get_price_history(condition_id, outcome):\n",
    "    # 한 번에 가격 히스토리를 가져오는 가정 (API 구현에 따라 조정 필요)\n",
    "    resp = client.get_price(condition_id, outcome)\n",
    "    return resp['history']\n",
    "\n",
    "def get_price_at_date_cached(condition_id, outcome, target_date_str):\n",
    "    price_history = get_price_history(condition_id, outcome)\n",
    "    target_date = datetime.strptime(target_date_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    target_ts = int(target_date.timestamp())  # 타임스탬프로 변환\n",
    "    \n",
    "    # 가장 가까운 시간대의 가격 찾기\n",
    "    closest_price = None\n",
    "    min_time_diff = float('inf')\n",
    "    for price_point in price_history:\n",
    "        time_diff = abs(price_point['t'] - target_ts)\n",
    "        if time_diff < min_time_diff:\n",
    "            min_time_diff = time_diff\n",
    "            closest_price = price_point['p']\n",
    "    return closest_price\n",
    "\n",
    "# 병렬 처리를 위한 함수\n",
    "def fetch_price_change(condition_id, date_str, offset):\n",
    "    target_date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    future_date = target_date + timedelta(days=offset)\n",
    "    future_date_str = future_date.strftime('%Y-%m-%d') + 'T00:00:00Z'\n",
    "    \n",
    "    target_yes_price = get_price_at_date_cached(condition_id, 'Yes', f\"{date_str}T00:00:00Z\")\n",
    "    future_yes_price = get_price_at_date_cached(condition_id, 'Yes', future_date_str)\n",
    "    \n",
    "    if target_yes_price is not None and future_yes_price is not None:\n",
    "        if future_yes_price > target_yes_price:\n",
    "            return 1  # 상승\n",
    "        elif future_yes_price < target_yes_price:\n",
    "            return -1  # 하락\n",
    "        else:\n",
    "            return 0  # 중립\n",
    "    return None\n",
    "\n",
    "# 메인 로직\n",
    "matching_df = pd.read_csv('matching_questions_rollcall_updated.csv')\n",
    "questions = matching_df['matching_questions'].tolist()\n",
    "dates = matching_df['date'].tolist()\n",
    "\n",
    "closed_trump_df = pd.read_csv('closed_trump_questions_description.csv')\n",
    "condition_ids = []\n",
    "for question in questions:\n",
    "    matched_row = closed_trump_df[closed_trump_df['question'] == question]\n",
    "    condition_ids.append(matched_row.iloc[0]['condition_id'] if not matched_row.empty else None)\n",
    "\n",
    "results = []\n",
    "offsets = [1, 3, 5]\n",
    "\n",
    "# 병렬 처리\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = []\n",
    "    for i, (condition_id, date_str) in enumerate(zip(condition_ids, dates)):\n",
    "        if condition_id is None:\n",
    "            continue\n",
    "        \n",
    "        # 타겟 날짜의 Yes 가격 조회\n",
    "        target_yes_price = get_price_at_date_cached(condition_id, 'Yes', f\"{date_str}T00:00:00Z\")\n",
    "        change_labels = {}\n",
    "        \n",
    "        # 미래 날짜 가격 조회 병렬 처리\n",
    "        for offset in offsets:\n",
    "            future = executor.submit(fetch_price_change, condition_id, date_str, offset)\n",
    "            futures.append((i, offset, future))\n",
    "        \n",
    "        results.append({\n",
    "            'question': questions[i],\n",
    "            'date': date_str,\n",
    "            'yes_price': target_yes_price,\n",
    "            **change_labels\n",
    "        })\n",
    "    \n",
    "    # 결과 수집\n",
    "    for i, offset, future in futures:\n",
    "        change_labels[f'change_{offset}d'] = future.result()\n",
    "        results[i].update(change_labels)\n",
    "\n",
    "# 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv('question_prices_with_changes.csv', index=False)\n",
    "print(\"가격 변동 라벨이 'question_prices_with_changes.csv'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표준편차 기반 변동성 라벨링이 'question_prices_with_volatility.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from clob_client import PolymarketClient, timestamp_to_datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import lru_cache\n",
    "\n",
    "# PolymarketClient 초기화\n",
    "client = PolymarketClient()\n",
    "\n",
    "# 캐싱을 위한 함수 정의\n",
    "@lru_cache(maxsize=100)\n",
    "def get_price_history(condition_id, outcome):\n",
    "    # 한 번에 가격 히스토리를 가져온다고 가정 (API 구현에 따라 조정 가능)\n",
    "    resp = client.get_price(condition_id, outcome)\n",
    "    return resp['history']\n",
    "\n",
    "def get_price_at_date_cached(condition_id, outcome, target_date_str):\n",
    "    \"\"\"\n",
    "    캐시된 price_history에서 target_date_str (예: '2025-03-14T00:00:00Z')와\n",
    "    가장 가까운 시간대의 가격을 찾아 반환\n",
    "    \"\"\"\n",
    "    price_history = get_price_history(condition_id, outcome)\n",
    "    target_date = datetime.strptime(target_date_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    target_ts = int(target_date.timestamp())  # 타임스탬프로 변환\n",
    "    \n",
    "    closest_price = None\n",
    "    min_time_diff = float('inf')\n",
    "    for price_point in price_history:\n",
    "        time_diff = abs(price_point['t'] - target_ts)\n",
    "        if time_diff < min_time_diff:\n",
    "            min_time_diff = time_diff\n",
    "            closest_price = price_point['p']\n",
    "    return closest_price\n",
    "\n",
    "def fetch_volatility(condition_id, base_date_str, days=5, threshold=0.03):\n",
    "    \"\"\"\n",
    "    base_date_str가 이미 'YYYY-MM-DDTHH:MM:SSZ' 형식이라고 가정.\n",
    "    base_date_str부터 days일(기본 5일) 뒤까지 매일 'Yes' 가격을 가져와\n",
    "    일별 수익률을 계산한 뒤, 표준편차가 threshold 초과 시 1, 아니면 0 반환\n",
    "    \"\"\"\n",
    "    # Day0 파싱\n",
    "    base_date = datetime.strptime(base_date_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    \n",
    "    # Day0 ~ Day5 가격 수집\n",
    "    daily_prices = []\n",
    "    for day_offset in range(days + 1):\n",
    "        check_date = base_date + timedelta(days=day_offset)\n",
    "        # 날짜를 그대로 '%Y-%m-%dT%H:%M:%SZ' 형식으로 포맷\n",
    "        check_date_str = check_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        \n",
    "        price = get_price_at_date_cached(condition_id, 'Yes', check_date_str)\n",
    "        daily_prices.append(price)\n",
    "\n",
    "    # 일별 수익률 계산\n",
    "    daily_returns = []\n",
    "    for i in range(len(daily_prices) - 1):\n",
    "        p1 = daily_prices[i]\n",
    "        p2 = daily_prices[i + 1]\n",
    "        if p1 is not None and p2 is not None and p1 != 0:\n",
    "            r = (p2 - p1) / p1\n",
    "            daily_returns.append(r)\n",
    "        else:\n",
    "            daily_returns.append(None)\n",
    "    \n",
    "    # None이 아닌 값만 골라 표본 표준편차 계산\n",
    "    valid_returns = [r for r in daily_returns if r is not None]\n",
    "    if len(valid_returns) > 1:\n",
    "        std_val = np.std(valid_returns, ddof=1)\n",
    "    else:\n",
    "        std_val = None\n",
    "    \n",
    "    # 표준편차가 임계값을 넘으면 변동성 영향 O(1), 아니면 X(0)\n",
    "    if std_val is not None and std_val > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 메인 로직\n",
    "df = pd.read_csv('merged_result.csv')\n",
    "questions = df['matching_questions'].tolist()\n",
    "dates = df['upload_date'].tolist()  \n",
    "condition_ids = df['condition_id'].tolist()\n",
    "results = []\n",
    "\n",
    "# 병렬 처리\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = []\n",
    "    for i, (condition_id, date_str) in enumerate(zip(condition_ids, dates)):\n",
    "        if condition_id is None or pd.isnull(date_str):\n",
    "            # condition_id 또는 날짜가 없으면 건너뜀\n",
    "            results.append({\n",
    "                'question': questions[i],\n",
    "                'date': date_str,\n",
    "                'volatility_label': None\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # 표준편차(5일 기준) → 변동성 임계값: 임의 예시(0.03)\n",
    "        future = executor.submit(fetch_volatility, condition_id, date_str, 5, 0.03)\n",
    "        futures.append((i, future))\n",
    "    \n",
    "    # 결과 수집\n",
    "    for i, future in futures:\n",
    "        label = future.result()\n",
    "        results.append({\n",
    "            'question': questions[i],\n",
    "            'date': dates[i],\n",
    "            'volatility_label': label\n",
    "        })\n",
    "\n",
    "# 결과 저장\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv('question_prices_with_volatility.csv', index=False)\n",
    "print(\"표준편차 기반 변동성 라벨링이 'question_prices_with_volatility.csv'에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keybert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
